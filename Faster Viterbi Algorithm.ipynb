{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences in training data 3718\n",
      "Total number of sentences in validation data 196\n",
      "Total number of words in training data 95615\n",
      "Total number of tags in training data 95615\n",
      "Total number of unique tags in training data 12\n",
      "Unique tags in training data {'ADP', 'NOUN', 'ADV', 'X', 'NUM', 'PRT', 'VERB', 'PRON', 'CONJ', '.', 'DET', 'ADJ'}\n"
     ]
    }
   ],
   "source": [
    "#Reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "\n",
    "#Splitting into train and validation data\n",
    "train_tagged_sentences, validation_tagged_sentences = train_test_split(nltk_data, train_size=0.95, random_state=9999)\n",
    "print('Total number of sentences in training data', len(train_tagged_sentences))\n",
    "print('Total number of sentences in validation data', len(validation_tagged_sentences))\n",
    "\n",
    "#Finding the tagged words from each sentence\n",
    "train_tagged_words=[word for sentence in train_tagged_sentences for word in sentence]\n",
    "train_tokens = [tagged_word[0] for tagged_word in train_tagged_words]\n",
    "print('Total number of words in training data', len(train_tokens))\n",
    "\n",
    "#Finding the tags from each sentence\n",
    "train_tags = [tagged_word[1] for tagged_word in train_tagged_words]\n",
    "print('Total number of tags in training data', len(train_tags))\n",
    "print('Total number of unique tags in training data', len(set(train_tags)))\n",
    "print('Unique tags in training data', set(train_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding data for Word given Tag count for Emission Probability data and Tag2 following Tag1 count for Transition Probability\n",
    "def emission_transition_data(word_bag):\n",
    "    tags = [tagged_word[1] for tagged_word in word_bag]\n",
    "    tags_count = dict(collections.Counter(tags))\n",
    "    \n",
    "    word_given_tag = [tagged_word[0] + '|' + tagged_word[1] for tagged_word in word_bag]\n",
    "    word_given_tag_count = dict(collections.Counter(word_given_tag))\n",
    "        \n",
    "    tag2_following_tag1 = [tags[index] + '-' + tags[index+1] for index in range(len(tags)-1)]\n",
    "    tag2_following_tag1_count = dict(collections.Counter(tag2_following_tag1))\n",
    "    \n",
    "    return tags_count, word_given_tag_count, tag2_following_tag1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viterbi Heuristic\n",
    "def Viterbi(words, words_bag):\n",
    "    tags_count, word_given_tag_count, tag2_following_tag1_count = emission_transition_data(words_bag)\n",
    "    tags = list(tags_count)\n",
    "    state = []\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #Initialising list of probability for a given observation\n",
    "        state_proba = [] \n",
    "        for tag in tags:\n",
    "            #Computing transition probabilities\n",
    "            if key == 0:\n",
    "                previous_tag = '.'                \n",
    "            else:\n",
    "                previous_tag = state[-1]\n",
    "                \n",
    "            transition_proba = tag2_following_tag1_count.get(previous_tag + '-' + tag, 0) / tags_count.get(previous_tag, 0)\n",
    "            \n",
    "            #Computing emission probabilities\n",
    "            emission_proba = word_given_tag_count.get(words[key] + '|' + tag, 0) / tags_count.get(tag, 0)\n",
    "            \n",
    "            #Computing state probabilities            \n",
    "            state_proba.append(emission_proba * transition_proba)\n",
    "            \n",
    "        #Getting state for which probability is maximum\n",
    "        max_state_proba = tags[state_proba.index(max(state_proba))] \n",
    "        state.append(max_state_proba)\n",
    "        \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging accuracy on training set 0.9771374784291168\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Training set accuracy\n",
    "words = train_tokens\n",
    "train_tagged_seq = Viterbi(words, train_tagged_words)\n",
    "check = [i for i, j in zip(train_tagged_seq, train_tagged_words) if i == j]\n",
    "train_accuracy = len(check)/len(train_tagged_seq)\n",
    "print('Tagging accuracy on training set', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging accuracy on validation set 0.9087136929460581\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Validation set accuracy\n",
    "validation_tagged_words=[word for sentence in validation_tagged_sentences for word in sentence]\n",
    "validation_tokens = [tagged_word[0] for tagged_word in validation_tagged_words]\n",
    "words = validation_tokens\n",
    "validation_tagged_seq_original = Viterbi(words, train_tagged_words)\n",
    "check = [i for i, j in zip(validation_tagged_seq_original, validation_tagged_words) if i == j]\n",
    "validation_accuracy = len(check)/len(validation_tagged_seq_original)\n",
    "print('Tagging accuracy on validation set', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
